{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    " \n",
    "ENStopWords = stopwords.words('english')\n",
    " \n",
    "def tokenize(text):\n",
    "    min_length = 3\n",
    "    words = map(lambda word: word.lower(), word_tokenize(text))\n",
    "    words = [word for word in words if word not in ENStopWords]\n",
    "    tokens = (list(map(lambda token: PorterStemmer().stem(token), words)))\n",
    "    p = re.compile('[a-zA-Z]+');\n",
    "    \n",
    "    filtered_tokens = list(filter (lambda token: p.match(token) and len(token) >= min_length, tokens))\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords, reuters\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import numpy as np\n",
    "# fix random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of document ids\n",
    "documents = reuters.fileids()\n",
    " \n",
    "train_docs_id = list(filter(lambda doc: doc.startswith('train'), documents))\n",
    "test_docs_id = list(filter(lambda doc: doc.startswith('test'), documents))\n",
    " \n",
    "train_docs = [reuters.raw(doc_id) for doc_id in train_docs_id]\n",
    "test_docs = [reuters.raw(doc_id) for doc_id in test_docs_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenisation\n",
    "vectorizer = TfidfVectorizer(stop_words=ENStopWords, tokenizer=tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['could', 'might', 'must', \"n't\", 'need', 'sha', 'would'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "# Learn and transform train documents\n",
    "vectorised_train_documents = vectorizer.fit_transform(train_docs)\n",
    "vectorised_test_documents = vectorizer.transform(test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7769x20682 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 370246 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorised_train_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3019x20682 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 128981 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorised_test_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform multilabel labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "train_labels = mlb.fit_transform([reuters.categories(doc_id) for doc_id in train_docs_id])\n",
    "test_labels = mlb.transform([reuters.categories(doc_id) for doc_id in test_docs_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "### 1st architecture\n",
    "\n",
    "The first architecture that will be tested is the simplest one - input layer with reasonable amount of neurons, activation and output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(20682,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(90))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6992 samples, validate on 777 samples\n",
      "Epoch 1/20\n",
      "6992/6992 [==============================] - 4s 523us/step - loss: 5.2116 - accuracy: 0.4890 - val_loss: 4.4646 - val_accuracy: 0.5792\n",
      "Epoch 2/20\n",
      "6992/6992 [==============================] - 4s 516us/step - loss: 3.8404 - accuracy: 0.6452 - val_loss: 2.9745 - val_accuracy: 0.6293\n",
      "Epoch 3/20\n",
      "6992/6992 [==============================] - 4s 509us/step - loss: 2.6602 - accuracy: 0.6869 - val_loss: 2.2387 - val_accuracy: 0.6860\n",
      "Epoch 4/20\n",
      "6992/6992 [==============================] - 4s 512us/step - loss: 2.0404 - accuracy: 0.7501 - val_loss: 1.8341 - val_accuracy: 0.7555\n",
      "Epoch 5/20\n",
      "6992/6992 [==============================] - 4s 512us/step - loss: 1.6724 - accuracy: 0.7953 - val_loss: 1.6168 - val_accuracy: 0.7799\n",
      "Epoch 6/20\n",
      "6992/6992 [==============================] - 4s 512us/step - loss: 1.5034 - accuracy: 0.8152 - val_loss: 1.5228 - val_accuracy: 0.7864\n",
      "Epoch 7/20\n",
      "6992/6992 [==============================] - 4s 518us/step - loss: 1.4553 - accuracy: 0.8314 - val_loss: 1.5271 - val_accuracy: 0.7838\n",
      "Epoch 8/20\n",
      "6992/6992 [==============================] - 4s 514us/step - loss: 1.4948 - accuracy: 0.8360 - val_loss: 1.5921 - val_accuracy: 0.7812\n",
      "Epoch 9/20\n",
      "6992/6992 [==============================] - 4s 514us/step - loss: 1.5878 - accuracy: 0.8411 - val_loss: 1.6867 - val_accuracy: 0.7761\n",
      "Epoch 10/20\n",
      "6992/6992 [==============================] - 4s 514us/step - loss: 1.7386 - accuracy: 0.8485 - val_loss: 1.8425 - val_accuracy: 0.7696\n",
      "Epoch 11/20\n",
      "6992/6992 [==============================] - 4s 514us/step - loss: 1.9291 - accuracy: 0.8458 - val_loss: 2.0166 - val_accuracy: 0.7658\n",
      "Epoch 12/20\n",
      "6992/6992 [==============================] - 4s 514us/step - loss: 2.1245 - accuracy: 0.8465 - val_loss: 2.1926 - val_accuracy: 0.7696\n",
      "Epoch 13/20\n",
      "6992/6992 [==============================] - 4s 514us/step - loss: 2.4065 - accuracy: 0.8468 - val_loss: 2.4280 - val_accuracy: 0.7671\n",
      "Epoch 14/20\n",
      "6992/6992 [==============================] - 4s 516us/step - loss: 2.7263 - accuracy: 0.8463 - val_loss: 2.6895 - val_accuracy: 0.7580\n",
      "Epoch 15/20\n",
      "6992/6992 [==============================] - 4s 527us/step - loss: 2.9975 - accuracy: 0.8480 - val_loss: 2.9611 - val_accuracy: 0.7709\n",
      "Epoch 16/20\n",
      "6992/6992 [==============================] - 4s 514us/step - loss: 3.4045 - accuracy: 0.8443 - val_loss: 3.2906 - val_accuracy: 0.7580\n",
      "Epoch 17/20\n",
      "6992/6992 [==============================] - 4s 514us/step - loss: 3.7487 - accuracy: 0.8444 - val_loss: 3.6090 - val_accuracy: 0.7503\n",
      "Epoch 18/20\n",
      "6992/6992 [==============================] - 4s 514us/step - loss: 4.2069 - accuracy: 0.8427 - val_loss: 3.9643 - val_accuracy: 0.7400\n",
      "Epoch 19/20\n",
      "6992/6992 [==============================] - 4s 518us/step - loss: 4.6657 - accuracy: 0.8411 - val_loss: 4.3147 - val_accuracy: 0.7542\n",
      "Epoch 20/20\n",
      "6992/6992 [==============================] - 4s 514us/step - loss: 5.0937 - accuracy: 0.8488 - val_loss: 4.7565 - val_accuracy: 0.7375\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(vectorised_train_documents, train_labels,\n",
    "                    batch_size=457,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3019/3019 [==============================] - 1s 207us/step\n",
      "Test score: 8.613382604825809\n",
      "Test accuracy: 0.7442861795425415\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(vectorised_test_documents, test_labels, batch_size=457, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(vectorised_test_documents)\n",
    "predictions_fixed = predictions > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-average quality numbers\n",
      "Precision: 0.9029, Recall: 0.6132, F1-measure: 0.7304\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(test_labels, predictions_fixed, average='micro')\n",
    "recall = recall_score(test_labels, predictions_fixed, average='micro')\n",
    "f1 = f1_score(test_labels, predictions_fixed, average='micro')\n",
    "\n",
    "print('Micro-average quality numbers')\n",
    "print('Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}'.format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-average quality numbers\n",
      "Precision: 0.2614, Recall: 0.1126, F1-measure: 0.1414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(test_labels, predictions_fixed, average='macro')\n",
    "recall = recall_score(test_labels, predictions_fixed, average='macro')\n",
    "f1 = f1_score(test_labels, predictions_fixed, average='macro')\n",
    "\n",
    "print('Macro-average quality numbers')\n",
    "print('Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}'.format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd architecture\n",
    "\n",
    "The second architecture will be identical to the first one, except one extra middle layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(20682,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(258))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(90))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6992 samples, validate on 777 samples\n",
      "Epoch 1/20\n",
      "6992/6992 [==============================] - 4s 529us/step - loss: 5.0766 - accuracy: 0.3430 - val_loss: 3.5894 - val_accuracy: 0.3771\n",
      "Epoch 2/20\n",
      "6992/6992 [==============================] - 4s 521us/step - loss: 3.1553 - accuracy: 0.4834 - val_loss: 2.4577 - val_accuracy: 0.6757\n",
      "Epoch 3/20\n",
      "6992/6992 [==============================] - 4s 521us/step - loss: 2.3426 - accuracy: 0.7029 - val_loss: 2.1655 - val_accuracy: 0.7220\n",
      "Epoch 4/20\n",
      "6992/6992 [==============================] - 4s 516us/step - loss: 2.3885 - accuracy: 0.7567 - val_loss: 2.6542 - val_accuracy: 0.7400\n",
      "Epoch 5/20\n",
      "6992/6992 [==============================] - 4s 518us/step - loss: 3.5721 - accuracy: 0.7845 - val_loss: 4.3344 - val_accuracy: 0.7194\n",
      "Epoch 6/20\n",
      "6992/6992 [==============================] - 4s 516us/step - loss: 6.4516 - accuracy: 0.7909 - val_loss: 7.5642 - val_accuracy: 0.7027\n",
      "Epoch 7/20\n",
      "6992/6992 [==============================] - 4s 518us/step - loss: 11.7803 - accuracy: 0.7633 - val_loss: 13.2295 - val_accuracy: 0.6332\n",
      "Epoch 8/20\n",
      "6992/6992 [==============================] - 4s 518us/step - loss: 22.4455 - accuracy: 0.6716 - val_loss: 26.4378 - val_accuracy: 0.4685\n",
      "Epoch 9/20\n",
      "6992/6992 [==============================] - 4s 518us/step - loss: 44.0257 - accuracy: 0.4823 - val_loss: 46.6458 - val_accuracy: 0.3642\n",
      "Epoch 10/20\n",
      "6992/6992 [==============================] - 4s 518us/step - loss: 80.4243 - accuracy: 0.4322 - val_loss: 83.1950 - val_accuracy: 0.3578\n",
      "Epoch 11/20\n",
      "6992/6992 [==============================] - 4s 521us/step - loss: 126.3411 - accuracy: 0.2939 - val_loss: 122.0256 - val_accuracy: 0.3900\n",
      "Epoch 12/20\n",
      "6992/6992 [==============================] - 4s 518us/step - loss: 145.6325 - accuracy: 0.4585 - val_loss: 143.1380 - val_accuracy: 0.5122\n",
      "Epoch 13/20\n",
      "6992/6992 [==============================] - 4s 518us/step - loss: 161.6604 - accuracy: 0.5223 - val_loss: 169.6167 - val_accuracy: 0.5251\n",
      "Epoch 14/20\n",
      "6992/6992 [==============================] - 4s 516us/step - loss: 215.0957 - accuracy: 0.3581 - val_loss: 258.7146 - val_accuracy: 0.2278\n",
      "Epoch 15/20\n",
      "6992/6992 [==============================] - 4s 521us/step - loss: 342.9310 - accuracy: 0.3099 - val_loss: 325.5211 - val_accuracy: 0.5199\n",
      "Epoch 16/20\n",
      "6992/6992 [==============================] - 4s 516us/step - loss: 363.9136 - accuracy: 0.3771 - val_loss: 306.5558 - val_accuracy: 0.3642\n",
      "Epoch 17/20\n",
      "6992/6992 [==============================] - 4s 518us/step - loss: 368.6853 - accuracy: 0.3152 - val_loss: 416.8002 - val_accuracy: 0.3784\n",
      "Epoch 18/20\n",
      "6992/6992 [==============================] - 4s 518us/step - loss: 473.6987 - accuracy: 0.2652 - val_loss: 433.3049 - val_accuracy: 0.2136\n",
      "Epoch 19/20\n",
      "6992/6992 [==============================] - 4s 518us/step - loss: 495.7654 - accuracy: 0.2217 - val_loss: 474.7385 - val_accuracy: 0.4414\n",
      "Epoch 20/20\n",
      "6992/6992 [==============================] - 4s 518us/step - loss: 523.7399 - accuracy: 0.4477 - val_loss: 527.5859 - val_accuracy: 0.0412\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(vectorised_train_documents, train_labels,\n",
    "                    batch_size=457,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3019/3019 [==============================] - 1s 207us/step\n",
      "Test score: 615.5082674737243\n",
      "Test accuracy: 0.06525339186191559\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(vectorised_test_documents, test_labels, batch_size=457, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(vectorised_test_documents)\n",
    "predictions_fixed = predictions > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-average quality numbers\n",
      "Precision: 0.0802, Recall: 0.0646, F1-measure: 0.0716\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(test_labels, predictions_fixed, average='micro')\n",
    "recall = recall_score(test_labels, predictions_fixed, average='micro')\n",
    "f1 = f1_score(test_labels, predictions_fixed, average='micro')\n",
    "\n",
    "print('Micro-average quality numbers')\n",
    "print('Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}'.format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-average quality numbers\n",
      "Precision: 0.0283, Recall: 0.0202, F1-measure: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(test_labels, predictions_fixed, average='macro')\n",
    "recall = recall_score(test_labels, predictions_fixed, average='macro')\n",
    "f1 = f1_score(test_labels, predictions_fixed, average='macro')\n",
    "\n",
    "print('Macro-average quality numbers')\n",
    "print('Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}'.format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3rd architecture\n",
    "\n",
    "The second architecture shows much worse results than the first one, even though we saw quite good accuracy at epoch 6. \n",
    "This looks like overfitting, thus lets try to add dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(20682,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(258))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(90))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6992 samples, validate on 777 samples\n",
      "Epoch 1/20\n",
      "6992/6992 [==============================] - 4s 536us/step - loss: 5.1250 - accuracy: 0.3541 - val_loss: 3.7227 - val_accuracy: 0.3771\n",
      "Epoch 2/20\n",
      "6992/6992 [==============================] - 4s 523us/step - loss: 3.4113 - accuracy: 0.4565 - val_loss: 2.6064 - val_accuracy: 0.6010\n",
      "Epoch 3/20\n",
      "6992/6992 [==============================] - 4s 523us/step - loss: 2.6088 - accuracy: 0.6118 - val_loss: 2.1777 - val_accuracy: 0.6641\n",
      "Epoch 4/20\n",
      "6992/6992 [==============================] - 4s 523us/step - loss: 2.4287 - accuracy: 0.6765 - val_loss: 2.2552 - val_accuracy: 0.7169\n",
      "Epoch 5/20\n",
      "6992/6992 [==============================] - 4s 525us/step - loss: 3.1655 - accuracy: 0.6703 - val_loss: 2.8827 - val_accuracy: 0.7259\n",
      "Epoch 6/20\n",
      "6992/6992 [==============================] - 4s 527us/step - loss: 5.4751 - accuracy: 0.6240 - val_loss: 4.5398 - val_accuracy: 0.7169\n",
      "Epoch 7/20\n",
      "6992/6992 [==============================] - 4s 529us/step - loss: 11.6766 - accuracy: 0.5355 - val_loss: 8.2255 - val_accuracy: 0.7066\n",
      "Epoch 8/20\n",
      "6992/6992 [==============================] - 4s 523us/step - loss: 23.6391 - accuracy: 0.4568 - val_loss: 15.0293 - val_accuracy: 0.6860\n",
      "Epoch 9/20\n",
      "6992/6992 [==============================] - 4s 523us/step - loss: 43.3350 - accuracy: 0.4208 - val_loss: 25.8608 - val_accuracy: 0.6538\n",
      "Epoch 10/20\n",
      "6992/6992 [==============================] - 4s 525us/step - loss: 71.2585 - accuracy: 0.3820 - val_loss: 36.8676 - val_accuracy: 0.6692\n",
      "Epoch 11/20\n",
      "6992/6992 [==============================] - 4s 525us/step - loss: 106.4978 - accuracy: 0.3503 - val_loss: 53.0349 - val_accuracy: 0.6371\n",
      "Epoch 12/20\n",
      "6992/6992 [==============================] - 4s 523us/step - loss: 150.3859 - accuracy: 0.3294 - val_loss: 74.0109 - val_accuracy: 0.5830\n",
      "Epoch 13/20\n",
      "6992/6992 [==============================] - 4s 527us/step - loss: 196.9144 - accuracy: 0.3262 - val_loss: 100.8986 - val_accuracy: 0.5959\n",
      "Epoch 14/20\n",
      "6992/6992 [==============================] - 4s 525us/step - loss: 253.2403 - accuracy: 0.2928 - val_loss: 122.6540 - val_accuracy: 0.5122\n",
      "Epoch 15/20\n",
      "6992/6992 [==============================] - 4s 523us/step - loss: 313.2788 - accuracy: 0.2712 - val_loss: 164.1602 - val_accuracy: 0.5405\n",
      "Epoch 16/20\n",
      "6992/6992 [==============================] - 4s 527us/step - loss: 366.5861 - accuracy: 0.2702 - val_loss: 208.6920 - val_accuracy: 0.6049\n",
      "Epoch 17/20\n",
      "6992/6992 [==============================] - 4s 529us/step - loss: 420.3354 - accuracy: 0.2540 - val_loss: 262.1863 - val_accuracy: 0.3784\n",
      "Epoch 18/20\n",
      "6992/6992 [==============================] - 4s 523us/step - loss: 485.7740 - accuracy: 0.2501 - val_loss: 280.3085 - val_accuracy: 0.4170\n",
      "Epoch 19/20\n",
      "6992/6992 [==============================] - 4s 523us/step - loss: 547.4640 - accuracy: 0.2523 - val_loss: 341.0043 - val_accuracy: 0.3822\n",
      "Epoch 20/20\n",
      "6992/6992 [==============================] - 4s 523us/step - loss: 585.2383 - accuracy: 0.2540 - val_loss: 405.9319 - val_accuracy: 0.5290\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(vectorised_train_documents, train_labels,\n",
    "                    batch_size=457,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3019/3019 [==============================] - 1s 207us/step\n",
      "Test score: 662.8224997784216\n",
      "Test accuracy: 0.5611129403114319\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(vectorised_test_documents, test_labels, batch_size=457, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(vectorised_test_documents)\n",
    "predictions_fixed = predictions > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-average quality numbers\n",
      "Precision: 0.5611, Recall: 0.4525, F1-measure: 0.5010\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(test_labels, predictions_fixed, average='micro')\n",
    "recall = recall_score(test_labels, predictions_fixed, average='micro')\n",
    "f1 = f1_score(test_labels, predictions_fixed, average='micro')\n",
    "\n",
    "print('Micro-average quality numbers')\n",
    "print('Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}'.format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-average quality numbers\n",
      "Precision: 0.0145, Recall: 0.0209, F1-measure: 0.0161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(test_labels, predictions_fixed, average='macro')\n",
    "recall = recall_score(test_labels, predictions_fixed, average='macro')\n",
    "f1 = f1_score(test_labels, predictions_fixed, average='macro')\n",
    "\n",
    "print('Macro-average quality numbers')\n",
    "print('Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}'.format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4th architecture\n",
    "\n",
    "It seems that the first simple approach works the best. Lets try to expand the network in the other direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2048, input_shape=(20682,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(90))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6992 samples, validate on 777 samples\n",
      "Epoch 1/20\n",
      "6992/6992 [==============================] - 12s 2ms/step - loss: 4.7327 - accuracy: 0.5715 - val_loss: 3.1789 - val_accuracy: 0.6448\n",
      "Epoch 2/20\n",
      "6992/6992 [==============================] - 11s 2ms/step - loss: 2.6752 - accuracy: 0.6786 - val_loss: 2.0425 - val_accuracy: 0.7169\n",
      "Epoch 3/20\n",
      "6992/6992 [==============================] - 11s 2ms/step - loss: 1.8063 - accuracy: 0.7848 - val_loss: 1.6122 - val_accuracy: 0.7799\n",
      "Epoch 4/20\n",
      "6992/6992 [==============================] - 11s 2ms/step - loss: 1.5170 - accuracy: 0.8242 - val_loss: 1.5754 - val_accuracy: 0.7838\n",
      "Epoch 5/20\n",
      "6992/6992 [==============================] - 11s 2ms/step - loss: 1.6123 - accuracy: 0.8370 - val_loss: 1.7786 - val_accuracy: 0.7812\n",
      "Epoch 6/20\n",
      "6992/6992 [==============================] - 11s 2ms/step - loss: 1.9033 - accuracy: 0.8451 - val_loss: 2.0379 - val_accuracy: 0.7735\n",
      "Epoch 7/20\n",
      "6992/6992 [==============================] - 11s 2ms/step - loss: 2.2804 - accuracy: 0.8495 - val_loss: 2.5019 - val_accuracy: 0.7580\n",
      "Epoch 8/20\n",
      "6992/6992 [==============================] - 11s 2ms/step - loss: 2.9617 - accuracy: 0.8444 - val_loss: 3.0243 - val_accuracy: 0.7761\n",
      "Epoch 9/20\n",
      "6992/6992 [==============================] - 11s 2ms/step - loss: 3.5948 - accuracy: 0.8461 - val_loss: 3.7519 - val_accuracy: 0.7568\n",
      "Epoch 10/20\n",
      "6992/6992 [==============================] - 12s 2ms/step - loss: 4.4665 - accuracy: 0.8412 - val_loss: 4.5018 - val_accuracy: 0.7426\n",
      "Epoch 11/20\n",
      "6992/6992 [==============================] - 11s 2ms/step - loss: 5.3204 - accuracy: 0.8427 - val_loss: 5.3298 - val_accuracy: 0.7310\n",
      "Epoch 12/20\n",
      "6992/6992 [==============================] - 11s 2ms/step - loss: 6.3354 - accuracy: 0.8381 - val_loss: 5.9646 - val_accuracy: 0.7555\n",
      "Epoch 13/20\n",
      "6992/6992 [==============================] - 11s 2ms/step - loss: 7.2719 - accuracy: 0.8428 - val_loss: 7.0698 - val_accuracy: 0.7207\n",
      "Epoch 14/20\n",
      "6992/6992 [==============================] - 11s 2ms/step - loss: 8.4477 - accuracy: 0.8394 - val_loss: 7.9733 - val_accuracy: 0.7079\n",
      "Epoch 15/20\n",
      "6992/6992 [==============================] - 11s 2ms/step - loss: 9.5747 - accuracy: 0.8298 - val_loss: 8.7793 - val_accuracy: 0.7246\n",
      "Epoch 16/20\n",
      "6992/6992 [==============================] - 11s 2ms/step - loss: 10.7670 - accuracy: 0.8342 - val_loss: 9.8774 - val_accuracy: 0.7362\n",
      "Epoch 17/20\n",
      "6992/6992 [==============================] - 12s 2ms/step - loss: 11.9503 - accuracy: 0.8320 - val_loss: 10.7845 - val_accuracy: 0.7117\n",
      "Epoch 18/20\n",
      "6992/6992 [==============================] - 11s 2ms/step - loss: 13.0648 - accuracy: 0.8279 - val_loss: 12.1352 - val_accuracy: 0.7053\n",
      "Epoch 19/20\n",
      "6992/6992 [==============================] - 11s 2ms/step - loss: 14.4232 - accuracy: 0.8238 - val_loss: 13.0215 - val_accuracy: 0.7079\n",
      "Epoch 20/20\n",
      "6992/6992 [==============================] - 11s 2ms/step - loss: 15.6548 - accuracy: 0.8261 - val_loss: 14.3482 - val_accuracy: 0.6937\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(vectorised_train_documents, train_labels,\n",
    "                    batch_size=457,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3019/3019 [==============================] - 1s 445us/step\n",
      "Test score: 27.348058948535797\n",
      "Test accuracy: 0.6840013265609741\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(vectorised_test_documents, test_labels, batch_size=457, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(vectorised_test_documents)\n",
    "predictions_fixed = predictions > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-average quality numbers\n",
      "Precision: 0.8154, Recall: 0.5900, F1-measure: 0.6846\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(test_labels, predictions_fixed, average='micro')\n",
    "recall = recall_score(test_labels, predictions_fixed, average='micro')\n",
    "f1 = f1_score(test_labels, predictions_fixed, average='micro')\n",
    "\n",
    "print('Micro-average quality numbers')\n",
    "print('Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}'.format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-average quality numbers\n",
      "Precision: 0.2476, Recall: 0.1096, F1-measure: 0.1314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(test_labels, predictions_fixed, average='macro')\n",
    "recall = recall_score(test_labels, predictions_fixed, average='macro')\n",
    "f1 = f1_score(test_labels, predictions_fixed, average='macro')\n",
    "\n",
    "print('Macro-average quality numbers')\n",
    "print('Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}'.format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the first simple approach works the best. In order to check other parameters, lets make a grid-search.\n",
    "# Parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(20682,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(90))\n",
    "    model.add(Activation('softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    }
   ],
   "source": [
    "# define the grid search parameters\n",
    "# first, tune batch size and epochs\n",
    "batch_size = [20, 100, 500, 1000]\n",
    "epochs = [10, 25, 50]\n",
    "\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(vectorised_train_documents, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.770756 using {'batch_size': 500, 'epochs': 10}\n"
     ]
    }
   ],
   "source": [
    "print('Best: %f using %s' % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets tune optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='adam'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(20682,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(90))\n",
    "    model.add(Activation('softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=500, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    }
   ],
   "source": [
    "# define the grid search parameters\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(vectorised_train_documents, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.994920 using {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "print('Best: %f using %s' % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune learning rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Nadam\n",
    "def create_model(learn_rate=0.01):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(20682,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(90))\n",
    "    model.add(Activation('softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Nadam(lr=learn_rate), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=500, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "param_grid = dict(learn_rate=learn_rate)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(vectorised_train_documents, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.995422 using {'learn_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "print('Best: %f using %s' % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune neuron activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Nadam\n",
    "def create_model(activation='relu'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(20682,)))\n",
    "    model.add(Activation(activation=activation))\n",
    "    model.add(Dense(90))\n",
    "    model.add(Activation('softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Nadam(lr=0.01), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=500, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid = dict(activation=activation)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(vectorised_train_documents, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.995529 using {'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "print('Best: %f using %s' % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Nadam\n",
    "def create_model(dropout_rate=0.0):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(20682,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(90))\n",
    "    model.add(Activation('softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Nadam(lr=0.01), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=500, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "param_grid = dict(dropout_rate=dropout_rate)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(vectorised_train_documents, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.995622 using {'dropout_rate': 0.2}\n"
     ]
    }
   ],
   "source": [
    "print('Best: %f using %s' % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(20682,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(90))\n",
    "model.add(Activation('softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer=Nadam(lr=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6992 samples, validate on 777 samples\n",
      "Epoch 1/10\n",
      "6992/6992 [==============================] - 4s 572us/step - loss: 0.0396 - accuracy: 0.9899 - val_loss: 0.0175 - val_accuracy: 0.9942\n",
      "Epoch 2/10\n",
      "6992/6992 [==============================] - 4s 541us/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 0.0119 - val_accuracy: 0.9957\n",
      "Epoch 3/10\n",
      "6992/6992 [==============================] - 4s 538us/step - loss: 0.0081 - accuracy: 0.9965 - val_loss: 0.0120 - val_accuracy: 0.9960\n",
      "Epoch 4/10\n",
      "6992/6992 [==============================] - 4s 538us/step - loss: 0.0067 - accuracy: 0.9968 - val_loss: 0.0113 - val_accuracy: 0.9960\n",
      "Epoch 5/10\n",
      "6992/6992 [==============================] - 4s 543us/step - loss: 0.0064 - accuracy: 0.9969 - val_loss: 0.0110 - val_accuracy: 0.9961\n",
      "Epoch 6/10\n",
      "6992/6992 [==============================] - 4s 541us/step - loss: 0.0062 - accuracy: 0.9969 - val_loss: 0.0111 - val_accuracy: 0.9960\n",
      "Epoch 7/10\n",
      "6992/6992 [==============================] - 4s 543us/step - loss: 0.0060 - accuracy: 0.9969 - val_loss: 0.0114 - val_accuracy: 0.9962\n",
      "Epoch 8/10\n",
      "6992/6992 [==============================] - 4s 538us/step - loss: 0.0059 - accuracy: 0.9969 - val_loss: 0.0111 - val_accuracy: 0.9962\n",
      "Epoch 9/10\n",
      "6992/6992 [==============================] - 4s 538us/step - loss: 0.0058 - accuracy: 0.9969 - val_loss: 0.0115 - val_accuracy: 0.9959\n",
      "Epoch 10/10\n",
      "6992/6992 [==============================] - 4s 545us/step - loss: 0.0057 - accuracy: 0.9969 - val_loss: 0.0112 - val_accuracy: 0.9962\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(vectorised_train_documents, train_labels,\n",
    "                    batch_size=500,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(vectorised_test_documents)\n",
    "predictions_fixed = predictions > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-average quality numbers\n",
      "Precision: 0.9565, Recall: 0.7166, F1-measure: 0.8194\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(test_labels, predictions_fixed, average='micro')\n",
    "recall = recall_score(test_labels, predictions_fixed, average='micro')\n",
    "f1 = f1_score(test_labels, predictions_fixed, average='micro')\n",
    "\n",
    "print('Micro-average quality numbers')\n",
    "print('Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}'.format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-average quality numbers\n",
      "Precision: 0.5819, Recall: 0.3037, F1-measure: 0.3693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(test_labels, predictions_fixed, average='macro')\n",
    "recall = recall_score(test_labels, predictions_fixed, average='macro')\n",
    "f1 = f1_score(test_labels, predictions_fixed, average='macro')\n",
    "\n",
    "print('Macro-average quality numbers')\n",
    "print('Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}'.format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3019/3019 [==============================] - 1s 212us/step\n",
      "Test score: 0.013759654011600812\n",
      "Test accuracy: 0.9956459999084473\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(vectorised_test_documents, test_labels, batch_size=457, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
